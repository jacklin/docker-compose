input {
    stdin {
    }
    jdbc {
      # mysql相关jdbc配置
      jdbc_connection_string => "jdbc:mysql://192.168.50.99:3306/www7723cn?zeroDateTimeBehavior=convertToNull&characterEncoding=utf8"
      jdbc_user => "sync_master"
      jdbc_password => "SyNc!(*$!)!$!)##198410141033"
       #处理中文乱码问题
      codec => plain { charset => "UTF-8"}
      # jdbc连接mysql驱动的文件目录，可去官网下载:https://dev.mysql.com/downloads/connector/j/
      jdbc_driver_library => "/usr/share/logstash/logstash-core/lib/jars/mysql-connector-java-5.1.46-bin.jar"
      # the name of the driver class for mysql
      jdbc_driver_class => "com.mysql.jdbc.Driver"
      jdbc_paging_enabled => "true"
      jdbc_page_size => "20"

      # mysql文件, 也可以直接写SQL语句在此处，如下：
      # statement => "SELECT * from ll_wadyx;"
      statement_filepath => "/usr/share/logstash/sql/jdbc.sql"

      # 这里类似crontab,可以定制定时操作，比如每10分钟执行一次同步(分 时 天 月 年)
      schedule => "* * * * *"

      # 是否记录上次执行结果, 如果为真,将会把上次执行到的 tracking_column 字段的值记录下来,保存到 last_run_metadata_path 指定的文件中
      record_last_run => "true"

      # 是否需要记录某个column 的值,如果record_last_run为真,可以自定义我们需要 track 的 column 名称，此时该参数就要为 true. 否则默认 track 的是 timestamp 的值.
      use_column_value => "true"

      # 如果 use_column_value 为真,需配置此参数. track 的数据库 column 名,该 column 必须是递增的. 一般是mysql主键
      tracking_column => "id"

      last_run_metadata_path => "/usr/share/logstash/last_id"

      # 是否清除 last_run_metadata_path 的记录,如果为真那么每次都相当于从头开始查询所有的数据库记录
      clean_run => "false"

      # 是否将 字段(column) 名称转小写
      lowercase_column_names => "false"
      #索引type
      type => "tag"
      #索引设置时区
      jdbc_default_timezone => "Asia/Shanghai"
    }
}

# 此处我不做过滤处理,如果需要，也可参考elk安装那篇
filter {}

output {
    # 输出到elasticsearch的配置
    elasticsearch {
        hosts => ["192.168.50.90:9200"]
        index => "ll_wadyx"
        # 将"_id"的值设为mysql的autoid字段
        document_id => "%{id}"
        template_overwrite => true
    }

    # 这里输出调试，正式运行时可以注释掉
    # stdout {
    #     codec => json_lines
    # }
}